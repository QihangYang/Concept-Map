{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What algorithms do we need?\n",
    "\n",
    "1.\tConcept $\\rightarrow$ Problem \n",
    "\n",
    "    1.\trecommendation\n",
    "\n",
    "1.\tProblem $\\rightarrow$ Concept  \n",
    "\n",
    "    1.\tidentify\n",
    "\n",
    "    1.\tprioritization\n",
    "\n",
    "1.\tConcept $\\rightarrow$ Concept \n",
    "\n",
    "    1.\trelationship\n",
    "\n",
    "1. Problem $\\rightarrow$ Problem\n",
    "    1. recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A complete procedure\n",
    "\n",
    "* Datasets\n",
    "\n",
    "    * **concepts_list**\n",
    "        * A list of concepts, and their meanings\n",
    "    * **questions_list**\n",
    "        * A list of questions, with their question ID, and some other information like year and author\n",
    "    * **concepts_graph**\n",
    "        * a dictionary of forward links and back links of each concept.\n",
    "    * **questions_concepts_matrix**\n",
    "        * If a concept is mensioned in a question, assign 1. If not, assign 0.\n",
    "    \n",
    "\n",
    "\n",
    "* Query a question\n",
    "\n",
    "    1. User import a image or pdf\n",
    "        1. Use OCR to convert it into text\n",
    "        1. Process data \n",
    "    \n",
    "    1. Match the question with our **concepts_list**\n",
    "        1. If a concept is included, assign 1. If not, assign 0.\n",
    "        1. For all the concepts included, find a path in **concepts_graph**\n",
    "        1. Print out the path and concepts\n",
    "        \n",
    "    1. Recommend similar questions.\n",
    "        1. For all the questions in the **questions_list**, calculate the distance between them and the target question.\n",
    "        1. Print out the ones have minimal distance.\n",
    "\n",
    "\n",
    "\n",
    "* Query concepts\n",
    "\n",
    "    1. User import several concepts\n",
    "        1. Give dynamic suggestions\n",
    "        \n",
    "    1. Print out the questions including these concepts\n",
    "        1. Weighted score\n",
    "    \n",
    "\n",
    "\n",
    "* Add a question\n",
    "    \n",
    "    1. User import a image or pdf\n",
    "        1. Use OCR to vonvert it into text(Latex?)\n",
    "    \n",
    "    1. Detect the concepts in the question\n",
    "    \n",
    "    1. Assign rights to user to edit the text and concepts\n",
    "    \n",
    "    \n",
    "* Add a concept\n",
    "\n",
    "    1. User import a concept\n",
    "        1. Give similar concepts suggestions\n",
    "        \n",
    "    1. Assign rights to user to edit the concept and its meaning\n",
    "    \n",
    "    1. Assign rights to user to choose the backlink and forwardlink of that concept\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query a question\n",
    "### 1. User: Input a image or pdf\n",
    "\n",
    "* OCR\n",
    "* NLP: stopwords, punctuation... (Math?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract as pt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "#nltk.download('wordnet')      #download if using this module for the first time\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')    #download if using this module for the first time\n",
    "\n",
    "#For Gensim\n",
    "import gensim\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3\n",
      "\n",
      "Recall that the th tted value ¥; can be expressed as a linear combination ofthe response\n",
      "values, ie,\n",
      "\n",
      "   \n",
      "\n",
      "Lh\n",
      "\n",
      " \n",
      "\n",
      "Problem 4\n",
      "\n",
      "Consider the regression through the origin model given by\n",
      "\n",
      "a Yiasut+a@ i=1,2...n  @#N(0,0%)\n",
      "‘The estimated model at observed point (2, y) is\n",
      "\n",
      "g= Be,\n",
      "\n",
      "where\n",
      "2)\n",
      "\n",
      "‘Complete the following tasks\n",
      "i. Show that\n",
      "\n",
      " \n",
      "\n",
      "is an unbiased estimator of\n",
      "ii, Compute the standard error of estimator 2.\n",
      "iii, Identify the probability distribution of estimator 3.\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# OCR converts image to text\n",
    "\n",
    "img1 = Image.open(\"page2.png\")\n",
    "ques1 = pt.image_to_string(img1)\n",
    "print(ques1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(document):\n",
    "    stopwordremoval = \" \".join([i for i in document.lower().split() if i not in stopwords])\n",
    "    punctuationremoval = ''.join(ch for ch in stopwordremoval if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punctuationremoval.split())\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before text-cleaning: Our board of directors boasts 11 seasoned technology and business leaders from Adobe, GSK, HGGC and more.\n"
     ]
    }
   ],
   "source": [
    "sample1 = \"Our board of directors boasts 11 seasoned technology and business leaders from Adobe, GSK, HGGC and more.\"\n",
    "sample2 = \"Our executives lead by example and guide us to accomplish great things every day.\"\n",
    "sample3 = \"Working at Pluralisght means being surrounded by smart, passionate people who inspire us to do our best work.\"\n",
    "sample4 = \"A leadership team with vision.\"\n",
    "sample5 = \"Courses on cloud, microservices, machine learning, security, Agile and more.\"\n",
    "sample6 = \"Interactive courses and projects.\"\n",
    "sample7 = \"Personalized course recommendations from Iris.\"\n",
    "sample8 = \"We’re excited to announce that Pluralsight has ranked #9 on the Great Place to Work 2018, Best Medium Workplaces list!\"\n",
    "sample9 = \"Few of the job opportunities include Implementation Consultant - Analytics, Manager - assessment production, Chief Information Officer, Director of Communications.\"\n",
    "\n",
    "# compile documents\n",
    "compileddoc = [sample1, sample2, sample3, sample4, sample5, sample6, sample7, sample8, sample9] \n",
    "\n",
    "final_doc = [clean(document).split() for document in compileddoc]\n",
    "print(\"Before text-cleaning:\", compileddoc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After text-cleaning: ['board', 'director', 'boast', '11', 'seasoned', 'technology', 'business', 'leader', 'adobe', 'gsk', 'hggc', 'more']\n"
     ]
    }
   ],
   "source": [
    "print(\"After text-cleaning:\",final_doc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Match the question with our concepts_list\n",
    "\n",
    "* Use LDA to detect the topics in the question (*Really need it?*)\n",
    "    \n",
    "* Compare the LDA topics with concepts_list\n",
    "    \n",
    "* If the topic is included in concepts_list, add a tag. If not, create a new concepts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.029*\"course\" + 0.028*\"u\" + 0.025*\"great\" + 0.021*\"work\" + 0.019*\"lead\"'), (1, '0.026*\"director\" + 0.024*\"course\" + 0.021*\"best\" + 0.021*\"more\" + 0.020*\"gsk\"')]\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "dictionary = corpora.Dictionary(final_doc)\n",
    "\n",
    "DT_matrix = [dictionary.doc2bow(doc) for doc in final_doc]\n",
    "\n",
    "Lda_object = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "lda_model_1 = Lda_object(DT_matrix, num_topics=2, id2word = dictionary)\n",
    "\n",
    "print(lda_model_1.print_topics(num_topics=2, num_words=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.034*\"course\" + 0.034*\"more\" + 0.032*\"director\" + 0.020*\"learning\" + 0.020*\"security\"'), (1, '0.031*\"best\" + 0.031*\"work\" + 0.030*\"u\" + 0.030*\"surrounded\" + 0.029*\"smart\"'), (2, '0.035*\"great\" + 0.033*\"ranked\" + 0.033*\"work\" + 0.033*\"we’re\" + 0.033*\"excited\"')]\n"
     ]
    }
   ],
   "source": [
    "lda_model_2 = Lda_object(DT_matrix, num_topics=3, id2word = dictionary)\n",
    "\n",
    "print(lda_model_2.print_topics(num_topics=3, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the shortest path in **concepts_graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          con1  con2  con3  con4  con5  con6  con7  con8  con9  con10\n",
      "quesID1      0     0     0     0     0     0     0     1     1      0\n",
      "quesID2      0     0     0     1     0     0     0     1     0      1\n",
      "quesID3      1     0     0     0     0     0     0     1     0      0\n",
      "quesID4      0     0     0     0     0     0     0     0     1      0\n",
      "quesID5      0     0     0     0     0     0     0     0     0      0\n",
      "quesID6      0     0     1     0     0     0     0     0     0      0\n",
      "quesID7      0     0     0     0     0     0     1     0     1      0\n",
      "quesID8      1     0     1     0     0     0     0     0     0      0\n",
      "quesID9      0     0     0     0     0     0     0     0     0      1\n",
      "quesID10     0     0     0     0     0     0     0     0     1      0\n"
     ]
    }
   ],
   "source": [
    "# Random questions_concepts_matrix\n",
    "\n",
    "concepts_list = [\"con1\", \"con2\", \"con3\", \"con4\", \"con5\", \"con6\", \"con7\", \"con8\", \"con9\", \"con10\"]\n",
    "ques_list = [\"quesID1\", \"quesID2\", \"quesID3\", \"quesID4\", \"quesID5\", \"quesID6\", \"quesID7\", \"quesID8\", \"quesID9\", \"quesID10\"]\n",
    "\n",
    "np.random.seed(0)\n",
    "ques_concepts = pd.DataFrame(data = np.random.binomial(size = 100, n = 1, p = 0.2).reshape(10, 10), \n",
    "                            index = ques_list, \n",
    "                            columns = concepts_list)\n",
    "print(ques_concepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'con1': ['con3', 'con5', 'con7', 'con9'], 'con2': ['con4'], 'con3': ['con5'], 'con4': ['con6'], 'con5': ['con8'], 'con6': [], 'con7': ['con10'], 'con8': ['con10'], 'con9': [], 'con10': []}\n"
     ]
    }
   ],
   "source": [
    "# A random concepts_graph\n",
    "\n",
    "concepts_graph = {\"con1\": [\"con3\", \"con5\", \"con7\", \"con9\"],\n",
    "                  \"con2\": [\"con4\"],\n",
    "                  \"con3\": [\"con5\"],\n",
    "                  \"con4\": [\"con6\"],\n",
    "                  \"con5\": [\"con8\"],\n",
    "                  \"con6\": [],\n",
    "                  \"con7\": [\"con10\"],\n",
    "                  \"con8\": [\"con10\"],\n",
    "                  \"con9\": [],\n",
    "                  \"con10\": []}\n",
    "\n",
    "print(concepts_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find shortest path functions\n",
    "\n",
    "def findShortestPath(graph, start, end, path=[]):\n",
    "    path = path + [start]\n",
    "    if start == end:\n",
    "        return path\n",
    "    \n",
    "    shortestPath = []\n",
    "    for node in graph[start]:\n",
    "        if node not in path:\n",
    "            newpath = findShortestPath(graph, node, end, path)\n",
    "            if newpath:\n",
    "                if not shortestPath or len(newpath)<len(shortestPath):\n",
    "                    shortestPath = newpath\n",
    "    return shortestPath\n",
    "\n",
    "\n",
    "def findConPath (quesID, ques_concepts, concepts_mat):\n",
    "    concepts = np.array(ques_concepts.loc[quesID, ques_concepts.loc[quesID] == 1].index)\n",
    "    n_con = len(concepts)\n",
    "    \n",
    "    path_list = []\n",
    "    for start in concepts:\n",
    "        for end in concepts[concepts != start]:\n",
    "            path = findShortestPath(concepts_graph, start, end, path_list)\n",
    "            if path:\n",
    "                path_list.append(path)\n",
    "    return(path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['con1', 'con5', 'con8']]\n"
     ]
    }
   ],
   "source": [
    "# The concepts path of quesID3\n",
    "quesID3_path = findConPath(\"quesID3\", ques_concepts, concepts_graph)\n",
    "print(quesID3_path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommend similar questions.\n",
    "\n",
    "* How to define distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance definition**\n",
    "\n",
    "Minkowski distance\n",
    "\n",
    "$$\n",
    "dist(X, Y) = \\left( \\sum_{i=1}^n |x_i - y_i|^p \\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "\n",
    "Jaccard similarity coefficient $\\surd$\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "\n",
    "Pearson correlation coefficient\n",
    "\n",
    "$$\n",
    "\\rho_{XY} = \\frac{\\sum_{i=1}^n (X_i - \\mu_X)(Y_i - \\mu_Y)}{\\sqrt{\\sum_{i=1}^n (X_i - \\mu_X)^2}\\sqrt{\\sum_{i=1}^n (Y_i - \\mu_Y)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between questions\n",
    "def distBtwQues(quesID1, quesID2, ques_concepts):\n",
    "    ques1_con = ques_concepts.loc[quesID1]\n",
    "    ques2_con = ques_concepts.loc[quesID2]\n",
    "    if sum((ques1_con + ques2_con) != 0) != 0:\n",
    "        Jdist = 1 - sum(ques1_con * ques2_con != 0) /sum((ques1_con + ques2_con) != 0)\n",
    "    else:\n",
    "        Jdist = 1\n",
    "    return(Jdist)\n",
    "\n",
    "\n",
    "# Find similar questions\n",
    "def findSimQues(quesID, ques_concepts):\n",
    "    ques_dis = []\n",
    "    for quesID2 in ques_concepts.index[ques_concepts.index != quesID]:\n",
    "        ques_dis.append(distBtwQues(quesID, quesID2, ques_concepts))\n",
    "    sort_index = np.argsort(ques_dis)\n",
    "    return(ques_concepts.index[sort_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           quesID1   quesID2   quesID3 quesID4 quesID5 quesID6   quesID7  \\\n",
      "quesID1          0      0.75  0.666667     0.5       1       1  0.666667   \n",
      "quesID2       0.75         0      0.75       1       1       1         1   \n",
      "quesID3   0.666667      0.75         0       1       1       1         1   \n",
      "quesID4        0.5         1         1       0       1       1       0.5   \n",
      "quesID5          1         1         1       1       1       1         1   \n",
      "quesID6          1         1         1       1       1       0         1   \n",
      "quesID7   0.666667         1         1     0.5       1       1         0   \n",
      "quesID8          1         1  0.666667       1       1     0.5         1   \n",
      "quesID9          1  0.666667         1       1       1       1         1   \n",
      "quesID10       0.5         1         1       0       1       1       0.5   \n",
      "\n",
      "           quesID8   quesID9 quesID10  \n",
      "quesID1          1         1      0.5  \n",
      "quesID2          1  0.666667        1  \n",
      "quesID3   0.666667         1        1  \n",
      "quesID4          1         1        0  \n",
      "quesID5          1         1        1  \n",
      "quesID6        0.5         1        1  \n",
      "quesID7          1         1      0.5  \n",
      "quesID8          0         1        1  \n",
      "quesID9          1         0        1  \n",
      "quesID10         1         1        0  \n"
     ]
    }
   ],
   "source": [
    "# Questions distances\n",
    "\n",
    "ques_dis_mat = pd.DataFrame(index = ques_list, columns = ques_list)\n",
    "for quesID1 in ques_list:\n",
    "    for quesID2 in ques_list:       \n",
    "        ques_dis_mat.loc[quesID1, quesID2] = distBtwQues(quesID1, quesID2, ques_concepts)\n",
    "print(ques_dis_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['quesID3', 'quesID9', 'quesID2', 'quesID6', 'quesID1', 'quesID4',\n",
      "       'quesID5', 'quesID7', 'quesID8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Similar questions for quesID1\n",
    "quesID1_min = findSimQues(\"quesID1\", ques_concepts)\n",
    "print(quesID1_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query concepts\n",
    "\n",
    "### 1. User import several concepts\n",
    "\n",
    "* Approximate string matching    \n",
    "\n",
    "### 2. Print out the questions including these concepts\n",
    "\n",
    "* Distance between question and concepts list\n",
    "    \n",
    "* Need to be weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance of all questions to the input concepts list\n",
    "def distToCons(input_cons, ques_concepts):\n",
    "    cons_list = np.zeros(len(ques_concepts.columns))\n",
    "    ques0 = pd.Series(cons_list, index = ques_concepts.columns)\n",
    "    ques0[input_cons] = 1\n",
    "    \n",
    "    ques_dist = []\n",
    "    for ques in np.array(ques_concepts.index):\n",
    "        ques_con = ques_concepts.loc[ques]\n",
    "        if sum((ques_con + ques0) != 0) != 0:\n",
    "            Jdist = 1 - sum(ques_con * ques0 != 0) /sum((ques_con + ques0) != 0)\n",
    "        else:\n",
    "            Jdist = 1\n",
    "        ques_dist.append(Jdist)\n",
    "        \n",
    "    sort_index = np.argsort(ques_dist)\n",
    "    return(ques_concepts.index[sort_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['quesID3', 'quesID1', 'quesID8', 'quesID2', 'quesID4', 'quesID5',\n",
      "       'quesID6', 'quesID7', 'quesID9', 'quesID10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Suppose that input \"con1\" and \"con8\"\n",
    "input_cons = [\"con1\", \"con8\"]\n",
    "\n",
    "recom_ques = distToCons(input_cons, ques_concepts)\n",
    "print(recom_ques)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
