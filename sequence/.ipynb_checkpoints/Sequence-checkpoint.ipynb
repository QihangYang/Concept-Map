{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from random import sample\n",
    "from math import floor\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def If_Concept(problems_df, concept):  \n",
    "    concepts = []\n",
    "    for n in problems_df.index:\n",
    "        if type(problems_df[\"Related_Concept\"][n]) != str:\n",
    "            concepts.append(0)\n",
    "            continue\n",
    "        if fuzz.partial_ratio(concept, problems_df[\"Related_Concept\"][n]) >= 90:\n",
    "            concepts.append(1)\n",
    "        else:\n",
    "            concepts.append(0)\n",
    "    return np.array(concepts)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def Text_To_Embedding(problem_text, embed_model, max_width = 500):\n",
    "    embed_list = []\n",
    "    words_list = problem_text.split()\n",
    "    for n in range(len(words_list)):\n",
    "        if words_list[n] in stopwords or len(words_list[n]) < 2:\n",
    "            continue\n",
    "        else:\n",
    "             try:\n",
    "                 embed_list.append(embed_model[words_list[n]])\n",
    "             except:\n",
    "                 pass\n",
    "       \n",
    "    if len(embed_list) < max_width:    \n",
    "        for n in range(len(embed_list), max_width):\n",
    "            embed_list.append(np.zeros(embed_model.vector_size))\n",
    "    else:\n",
    "        embed_list = embed_list[:max_width]\n",
    "    return np.array(embed_list)\n",
    "\n",
    "    \n",
    "def Create_Embedding(problems, embed_model, max_width = 500):\n",
    "    embed_mat = []\n",
    "    for index in problems.index:\n",
    "        if type(problems[index]) != str:\n",
    "            embed_mat.append(Text_To_Embedding(\" \", embed_model, max_width = max_width))\n",
    "            continue\n",
    "        embed_mat.append(Text_To_Embedding(problems[index], embed_model, max_width = max_width))\n",
    "    return np.array(embed_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases: 183\n",
      "Negative cases: 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "problems = pd.read_csv(\"problem_2.csv\")\n",
    "embed_model = Word2Vec.load(\"embed_model_2\")\n",
    "\n",
    "# Choose a concept\n",
    "#concept_text = \"Simple Linear Regression\" # 226/295\n",
    "#concept_text = \"Multiple Linear Regression\" # 152/369\n",
    "#concept_text = \"Hypothesis Testing\" #112/409\n",
    "concept_text = \"Estimation\" # 183/338\n",
    "\n",
    "# Training and test sets\n",
    "Full_concept = If_Concept(problems, concept_text)\n",
    "Full_pos = problems[Full_concept == 1]\n",
    "print(\"Positive cases: %i\" % Full_pos.shape[0])\n",
    "Full_neg = problems[Full_concept == 0]\n",
    "print(\"Negative cases: %i\" % Full_neg.shape[0])\n",
    "\n",
    "np.random.seed(1)\n",
    "Train_pos = Full_pos.sample(floor(0.9 * Full_pos.shape[0]))\n",
    "Test_pos = Full_pos.drop(Train_pos.index)\n",
    "Train_neg = Full_neg.sample(floor(0.9 * Full_neg.shape[0]))\n",
    "Test_neg = Full_neg.drop(Train_neg.index)\n",
    "\n",
    "Train_problems_df = Train_pos.append(Train_neg)\n",
    "Train_problems = Train_problems_df[\"Problem_text\"]\n",
    "Test_problems_df = Test_pos.append(Test_neg)\n",
    "Test_problems = Test_problems_df[\"Problem_text\"]\n",
    "\n",
    "Train_X = Create_Embedding(Train_problems, embed_model, max_width = 50)\n",
    "Test_X = Create_Embedding(Test_problems, embed_model, max_width = 50)\n",
    "\n",
    "Train_Y = If_Concept(Train_problems_df, concept_text)\n",
    "Test_Y = If_Concept(Test_problems_df, concept_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 468 samples, validate on 53 samples\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 2s 4ms/step - loss: 0.6717 - accuracy: 0.6175 - val_loss: 0.6685 - val_accuracy: 0.6415\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.7051 - val_loss: 0.5626 - val_accuracy: 0.7547\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7799 - val_loss: 0.5169 - val_accuracy: 0.7358\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7628 - val_loss: 0.5657 - val_accuracy: 0.6981\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7714 - val_loss: 0.5448 - val_accuracy: 0.7170\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7735 - val_loss: 0.4959 - val_accuracy: 0.7358\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.4947 - accuracy: 0.7970 - val_loss: 0.5049 - val_accuracy: 0.7736\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7799 - val_loss: 0.5003 - val_accuracy: 0.7547\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7949 - val_loss: 0.4986 - val_accuracy: 0.7925\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7906 - val_loss: 0.4972 - val_accuracy: 0.8113\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) # sigmoid\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(Train_X, Train_Y, validation_data=(Test_X, Test_Y), epochs=10, batch_size=64)\n",
    "\n",
    "scores = model.evaluate(Test_X, Test_Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.58%\n",
      "[[1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Simple Linear Regression 73.58%\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "Simple_prediction = np.transpose([a for a in model.predict_classes(Test_X)])\n",
    "Simple_Test_y = Test_Y\n",
    "print(Simple_prediction)\n",
    "print(Simple_Test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.47%\n",
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression 75%\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "Multiple_prediction = np.transpose([a for a in model.predict_classes(Test_X)])\n",
    "Multiple_Test_y = Test_Y\n",
    "print(Multiple_prediction)\n",
    "print(Multiple_Test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.91%\n",
      "[[0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis Testing 84.91%\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "Hypo_prediction = np.transpose([a for a in model.predict_classes(Test_X)])\n",
    "Hypo_Test_y = Test_Y\n",
    "print(Hypo_prediction)\n",
    "print(Hypo_Test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.13%\n",
      "[[1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Estimation 79.25%\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "Estimation_prediction = np.transpose([a for a in model.predict_classes(Test_X)])\n",
    "Estimation_Test_y = Test_Y\n",
    "print(Estimation_prediction)\n",
    "print(Estimation_Test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
